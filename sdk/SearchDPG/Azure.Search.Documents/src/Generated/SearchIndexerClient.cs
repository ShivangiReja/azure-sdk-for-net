// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Threading.Tasks;
using Azure;
using Azure.Core;
using Azure.Core.Pipeline;

namespace Azure.Search.Documents.Indexes
{
    // Data plane generated client. The SearchIndexer service client.
    /// <summary> The SearchIndexer service client. </summary>
    public partial class SearchIndexerClient
    {
        private readonly HttpPipeline _pipeline;
        private readonly string _endpoint;
        private readonly Guid? _xMsClientRequestId;
        private readonly string _apiVersion;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        public virtual HttpPipeline Pipeline => _pipeline;

        /// <summary> Initializes a new instance of SearchIndexerClient for mocking. </summary>
        protected SearchIndexerClient()
        {
        }

        /// <summary> Initializes a new instance of SearchIndexerClient. </summary>
        /// <param name="endpoint"> The endpoint URL of the search service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> is null. </exception>
        public SearchIndexerClient(string endpoint) : this(endpoint, null, new SearchClientOptions())
        {
        }

        /// <summary> Initializes a new instance of SearchIndexerClient. </summary>
        /// <param name="endpoint"> The endpoint URL of the search service. </param>
        /// <param name="xMsClientRequestId"> The tracking ID sent with the request to help with debugging. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> is null. </exception>
        public SearchIndexerClient(string endpoint, Guid? xMsClientRequestId, SearchClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            options ??= new SearchClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), Array.Empty<HttpPipelinePolicy>(), new ResponseClassifier());
            _endpoint = endpoint;
            _xMsClientRequestId = xMsClientRequestId;
            _apiVersion = options.Version;
        }

        /// <summary> Resets the change tracking state associated with an indexer. </summary>
        /// <param name="indexerName"> The name of the indexer to reset. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <example>
        /// This sample shows how to call ResetAsync with required parameters.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.ResetAsync("<indexerName>");
        /// Console.WriteLine(response.Status);
        /// ]]></code>
        /// </example>
        public virtual async Task<Response> ResetAsync(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.Reset");
            scope.Start();
            try
            {
                using HttpMessage message = CreateResetRequest(indexerName, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Resets the change tracking state associated with an indexer. </summary>
        /// <param name="indexerName"> The name of the indexer to reset. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <example>
        /// This sample shows how to call Reset with required parameters.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.Reset("<indexerName>");
        /// Console.WriteLine(response.Status);
        /// ]]></code>
        /// </example>
        public virtual Response Reset(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.Reset");
            scope.Start();
            try
            {
                using HttpMessage message = CreateResetRequest(indexerName, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Runs an indexer on-demand. </summary>
        /// <param name="indexerName"> The name of the indexer to run. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <example>
        /// This sample shows how to call RunAsync with required parameters.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.RunAsync("<indexerName>");
        /// Console.WriteLine(response.Status);
        /// ]]></code>
        /// </example>
        public virtual async Task<Response> RunAsync(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.Run");
            scope.Start();
            try
            {
                using HttpMessage message = CreateRunRequest(indexerName, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Runs an indexer on-demand. </summary>
        /// <param name="indexerName"> The name of the indexer to run. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        /// <example>
        /// This sample shows how to call Run with required parameters.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.Run("<indexerName>");
        /// Console.WriteLine(response.Status);
        /// ]]></code>
        /// </example>
        public virtual Response Run(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.Run");
            scope.Start();
            try
            {
                using HttpMessage message = CreateRunRequest(indexerName, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Creates a new indexer or updates an indexer if it already exists. </summary>
        /// <param name="indexerName"> The name of the indexer to create or update. </param>
        /// <param name="content"> The content to send as the body of the request. Details of the request body schema are in the Remarks section below. </param>
        /// <param name="matchConditions"> The content to send as the request conditions of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> or <paramref name="content"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call CreateOrUpdateAsync with required parameters and request content, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// var data = new {
        ///     name = "<name>",
        ///     dataSource = new {
        ///         name = "<name>",
        ///         type = "azuresql",
        ///         credentials = new {},
        ///         container = new {
        ///             name = "<name>",
        ///         },
        ///     },
        /// };
        /// 
        /// Response response = await client.CreateOrUpdateAsync("<indexerName>", RequestContent.Create(data));
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// ]]></code>
        /// This sample shows how to call CreateOrUpdateAsync with all parameters and request content, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// var data = new {
        ///     name = "<name>",
        ///     description = "<description>",
        ///     dataSource = new {
        ///         name = "<name>",
        ///         description = "<description>",
        ///         type = "azuresql",
        ///         credentials = new {
        ///             connectionString = "<connectionString>",
        ///         },
        ///         container = new {
        ///             name = "<name>",
        ///             query = "<query>",
        ///         },
        ///         dataChangeDetectionPolicy = new {
        ///             highWaterMarkColumnName = "<highWaterMarkColumnName>",
        ///             @odata.type = "#Microsoft.Azure.Search.HighWaterMarkChangeDetectionPolicy",
        ///         },
        ///         dataDeletionDetectionPolicy = new {
        ///             softDeleteColumnName = "<softDeleteColumnName>",
        ///             softDeleteMarkerValue = "<softDeleteMarkerValue>",
        ///             @odata.type = "#Microsoft.Azure.Search.SoftDeleteColumnDeletionDetectionPolicy",
        ///         },
        ///         @odata.etag = "<@odata.etag>",
        ///     },
        ///     skillset = new {
        ///         name = "<name>",
        ///         description = "<description>",
        ///         skills = new[] {
        ///             new {
        ///                 @odata.type = "#Microsoft.Skills.Util.ConditionalSkill",
        ///                 name = "<name>",
        ///                 description = "<description>",
        ///                 context = "<context>",
        ///                 inputs = new[] {
        ///                     new {
        ///                         name = "<name>",
        ///                         source = "<source>",
        ///                         sourceContext = "<sourceContext>",
        ///                         inputs = new[] {},
        ///                     }
        ///                 },
        ///                 outputs = new[] {
        ///                     new {
        ///                         name = "<name>",
        ///                         targetName = "<targetName>",
        ///                     }
        ///                 },
        ///             }
        ///         },
        ///         cognitiveServices = new {
        ///             @odata.type = "#Microsoft.Azure.Search.DefaultCognitiveServices",
        ///             description = "<description>",
        ///         },
        ///         knowledgeStore = new {
        ///             storageConnectionString = "<storageConnectionString>",
        ///             projections = new[] {
        ///                 new {
        ///                     tables = new[] {
        ///                         new {
        ///                             tableName = "<tableName>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                     objects = new[] {
        ///                         new {
        ///                             storageContainer = "<storageContainer>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                     files = new[] {
        ///                         new {
        ///                             storageContainer = "<storageContainer>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                 }
        ///             },
        ///         },
        ///         @odata.etag = "<@odata.etag>",
        ///     },
        ///     schedule = new {
        ///         interval = PT1H23M45S,
        ///         startTime = "2022-05-10T18:57:31.2311892Z",
        ///     },
        ///     parameters = new {
        ///         batchSize = 1234,
        ///         maxFailedItems = 1234,
        ///         maxFailedItemsPerBatch = 1234,
        ///         configuration = new {
        ///             parsingMode = "default",
        ///             excludedFileNameExtensions = "<excludedFileNameExtensions>",
        ///             indexedFileNameExtensions = "<indexedFileNameExtensions>",
        ///             failOnUnsupportedContentType = true,
        ///             failOnUnprocessableDocument = true,
        ///             indexStorageMetadataOnlyForOversizedDocuments = true,
        ///             delimitedTextHeaders = "<delimitedTextHeaders>",
        ///             delimitedTextDelimiter = "<delimitedTextDelimiter>",
        ///             firstLineContainsHeaders = true,
        ///             documentRoot = "<documentRoot>",
        ///             dataToExtract = "storageMetadata",
        ///             imageAction = "none",
        ///             allowSkillsetToReadFileData = true,
        ///             pdfTextRotationAlgorithm = "none",
        ///             executionEnvironment = "standard",
        ///             queryTimeout = "<queryTimeout>",
        ///         },
        ///     },
        ///     fieldMappings = new[] {
        ///         new {
        ///             sourceFieldName = "<sourceFieldName>",
        ///             targetFieldName = "<targetFieldName>",
        ///             mappingFunction = new {
        ///                 name = "<name>",
        ///                 parameters = new {
        ///                     key = new {},
        ///                 },
        ///             },
        ///         }
        ///     },
        ///     outputFieldMappings = new[] {
        ///         new {
        ///             sourceFieldName = "<sourceFieldName>",
        ///             targetFieldName = "<targetFieldName>",
        ///             mappingFunction = new {
        ///                 name = "<name>",
        ///                 parameters = new {
        ///                     key = new {},
        ///                 },
        ///             },
        ///         }
        ///     },
        ///     disabled = true,
        ///     @odata.etag = "<@odata.etag>",
        /// };
        /// 
        /// Response response = await client.CreateOrUpdateAsync("<indexerName>", RequestContent.Create(data), new MatchConditions { IfMatch = "<YOUR_ETAG>" });
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the request and response payloads.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Create-Indexer
        /// 
        /// Request Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual async Task<Response> CreateOrUpdateAsync(string indexerName, RequestContent content, MatchConditions matchConditions = null, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.CreateOrUpdate");
            scope.Start();
            try
            {
                using HttpMessage message = CreateCreateOrUpdateRequest(indexerName, content, matchConditions, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Creates a new indexer or updates an indexer if it already exists. </summary>
        /// <param name="indexerName"> The name of the indexer to create or update. </param>
        /// <param name="content"> The content to send as the body of the request. Details of the request body schema are in the Remarks section below. </param>
        /// <param name="matchConditions"> The content to send as the request conditions of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> or <paramref name="content"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call CreateOrUpdate with required parameters and request content, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// var data = new {
        ///     name = "<name>",
        ///     dataSource = new {
        ///         name = "<name>",
        ///         type = "azuresql",
        ///         credentials = new {},
        ///         container = new {
        ///             name = "<name>",
        ///         },
        ///     },
        /// };
        /// 
        /// Response response = client.CreateOrUpdate("<indexerName>", RequestContent.Create(data));
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// ]]></code>
        /// This sample shows how to call CreateOrUpdate with all parameters and request content, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// var data = new {
        ///     name = "<name>",
        ///     description = "<description>",
        ///     dataSource = new {
        ///         name = "<name>",
        ///         description = "<description>",
        ///         type = "azuresql",
        ///         credentials = new {
        ///             connectionString = "<connectionString>",
        ///         },
        ///         container = new {
        ///             name = "<name>",
        ///             query = "<query>",
        ///         },
        ///         dataChangeDetectionPolicy = new {
        ///             highWaterMarkColumnName = "<highWaterMarkColumnName>",
        ///             @odata.type = "#Microsoft.Azure.Search.HighWaterMarkChangeDetectionPolicy",
        ///         },
        ///         dataDeletionDetectionPolicy = new {
        ///             softDeleteColumnName = "<softDeleteColumnName>",
        ///             softDeleteMarkerValue = "<softDeleteMarkerValue>",
        ///             @odata.type = "#Microsoft.Azure.Search.SoftDeleteColumnDeletionDetectionPolicy",
        ///         },
        ///         @odata.etag = "<@odata.etag>",
        ///     },
        ///     skillset = new {
        ///         name = "<name>",
        ///         description = "<description>",
        ///         skills = new[] {
        ///             new {
        ///                 @odata.type = "#Microsoft.Skills.Util.ConditionalSkill",
        ///                 name = "<name>",
        ///                 description = "<description>",
        ///                 context = "<context>",
        ///                 inputs = new[] {
        ///                     new {
        ///                         name = "<name>",
        ///                         source = "<source>",
        ///                         sourceContext = "<sourceContext>",
        ///                         inputs = new[] {},
        ///                     }
        ///                 },
        ///                 outputs = new[] {
        ///                     new {
        ///                         name = "<name>",
        ///                         targetName = "<targetName>",
        ///                     }
        ///                 },
        ///             }
        ///         },
        ///         cognitiveServices = new {
        ///             @odata.type = "#Microsoft.Azure.Search.DefaultCognitiveServices",
        ///             description = "<description>",
        ///         },
        ///         knowledgeStore = new {
        ///             storageConnectionString = "<storageConnectionString>",
        ///             projections = new[] {
        ///                 new {
        ///                     tables = new[] {
        ///                         new {
        ///                             tableName = "<tableName>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                     objects = new[] {
        ///                         new {
        ///                             storageContainer = "<storageContainer>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                     files = new[] {
        ///                         new {
        ///                             storageContainer = "<storageContainer>",
        ///                             referenceKeyName = "<referenceKeyName>",
        ///                             generatedKeyName = "<generatedKeyName>",
        ///                             source = "<source>",
        ///                             sourceContext = "<sourceContext>",
        ///                             inputs = new[] {
        ///                                 new {
        ///                                     name = "<name>",
        ///                                     source = "<source>",
        ///                                     sourceContext = "<sourceContext>",
        ///                                     inputs = new[] {},
        ///                                 }
        ///                             },
        ///                         }
        ///                     },
        ///                 }
        ///             },
        ///         },
        ///         @odata.etag = "<@odata.etag>",
        ///     },
        ///     schedule = new {
        ///         interval = PT1H23M45S,
        ///         startTime = "2022-05-10T18:57:31.2311892Z",
        ///     },
        ///     parameters = new {
        ///         batchSize = 1234,
        ///         maxFailedItems = 1234,
        ///         maxFailedItemsPerBatch = 1234,
        ///         configuration = new {
        ///             parsingMode = "default",
        ///             excludedFileNameExtensions = "<excludedFileNameExtensions>",
        ///             indexedFileNameExtensions = "<indexedFileNameExtensions>",
        ///             failOnUnsupportedContentType = true,
        ///             failOnUnprocessableDocument = true,
        ///             indexStorageMetadataOnlyForOversizedDocuments = true,
        ///             delimitedTextHeaders = "<delimitedTextHeaders>",
        ///             delimitedTextDelimiter = "<delimitedTextDelimiter>",
        ///             firstLineContainsHeaders = true,
        ///             documentRoot = "<documentRoot>",
        ///             dataToExtract = "storageMetadata",
        ///             imageAction = "none",
        ///             allowSkillsetToReadFileData = true,
        ///             pdfTextRotationAlgorithm = "none",
        ///             executionEnvironment = "standard",
        ///             queryTimeout = "<queryTimeout>",
        ///         },
        ///     },
        ///     fieldMappings = new[] {
        ///         new {
        ///             sourceFieldName = "<sourceFieldName>",
        ///             targetFieldName = "<targetFieldName>",
        ///             mappingFunction = new {
        ///                 name = "<name>",
        ///                 parameters = new {
        ///                     key = new {},
        ///                 },
        ///             },
        ///         }
        ///     },
        ///     outputFieldMappings = new[] {
        ///         new {
        ///             sourceFieldName = "<sourceFieldName>",
        ///             targetFieldName = "<targetFieldName>",
        ///             mappingFunction = new {
        ///                 name = "<name>",
        ///                 parameters = new {
        ///                     key = new {},
        ///                 },
        ///             },
        ///         }
        ///     },
        ///     disabled = true,
        ///     @odata.etag = "<@odata.etag>",
        /// };
        /// 
        /// Response response = client.CreateOrUpdate("<indexerName>", RequestContent.Create(data), new MatchConditions { IfMatch = "<YOUR_ETAG>" });
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the request and response payloads.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Create-Indexer
        /// 
        /// Request Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual Response CreateOrUpdate(string indexerName, RequestContent content, MatchConditions matchConditions = null, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.CreateOrUpdate");
            scope.Start();
            try
            {
                using HttpMessage message = CreateCreateOrUpdateRequest(indexerName, content, matchConditions, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Retrieves an indexer definition. </summary>
        /// <param name="indexerName"> The name of the indexer to retrieve. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetSearchIndexerAsync with required parameters and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.GetSearchIndexerAsync("<indexerName>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Get-Indexer
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual async Task<Response> GetSearchIndexerAsync(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetSearchIndexer");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetSearchIndexerRequest(indexerName, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Retrieves an indexer definition. </summary>
        /// <param name="indexerName"> The name of the indexer to retrieve. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetSearchIndexer with required parameters and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.GetSearchIndexer("<indexerName>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Get-Indexer
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexer</c>:
        /// <code>{
        ///   name: string, # Required. The name of the indexer.
        ///   description: string, # Optional. The description of the indexer.
        ///   dataSource: {
        ///     name: string, # Required. The name of the datasource.
        ///     description: string, # Optional. The description of the datasource.
        ///     type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///     credentials: {
        ///       connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///     }, # Required. Credentials for the datasource.
        ///     container: {
        ///       name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///       query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///     }, # Required. The data container for the datasource.
        ///     dataChangeDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///     }, # Optional. The data change detection policy for the datasource.
        ///     dataDeletionDetectionPolicy: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///     }, # Optional. The data deletion detection policy for the datasource.
        ///     @odata.etag: string, # Optional. The ETag of the data source.
        ///   }, # Required. The name of the datasource from which this indexer reads data.
        ///   skillset: {
        ///     name: string, # Required. The name of the skillset.
        ///     description: string, # Optional. The description of the skillset.
        ///     skills: [
        ///       {
        ///         @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///         name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///         description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///         context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///         inputs: [
        ///           {
        ///             name: string, # Required. The name of the input.
        ///             source: string, # Optional. The source of the input.
        ///             sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///             inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///           }
        ///         ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///         outputs: [
        ///           {
        ///             name: string, # Required. The name of the output defined by the skill.
        ///             targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///           }
        ///         ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///       }
        ///     ], # Required. A list of skills in the skillset.
        ///     cognitiveServices: {
        ///       @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///       description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///     }, # Optional. Details about cognitive services to be used when running skills.
        ///     knowledgeStore: {
        ///       storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///       projections: [
        ///         {
        ///           tables: [
        ///             {
        ///               tableName: string, # Required. Name of the Azure table to store projected data in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Table storage.
        ///           objects: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure Blob storage.
        ///           files: [
        ///             {
        ///               storageContainer: string, # Required. Blob container to store projections in.
        ///               referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///               generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///               source: string, # Optional. Source data to project.
        ///               sourceContext: string, # Optional. Source context for complex projections.
        ///               inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///             }
        ///           ], # Optional. Projections to Azure File storage.
        ///         }
        ///       ], # Required. A list of additional projections to perform during indexing.
        ///     }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///     @odata.etag: string, # Optional. The ETag of the skillset.
        ///   }, # Optional. The name of the skillset executing with this indexer.
        ///   schedule: {
        ///     interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///     startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///   }, # Optional. The schedule for this indexer.
        ///   parameters: {
        ///     batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///     maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///     maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///     configuration: {
        ///       parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///       excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///       indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///       failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///       failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///       indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///       delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///       delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///       firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///       documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///       dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///       imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///       allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///       pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///       executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///       queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///     }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///   }, # Optional. Parameters for indexer execution.
        ///   fieldMappings: [
        ///     {
        ///       sourceFieldName: string, # Required. The name of the field in the data source.
        ///       targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///       mappingFunction: {
        ///         name: string, # Required. The name of the field mapping function.
        ///         parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///       }, # Optional. A function to apply to each source field value before indexing.
        ///     }
        ///   ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///   outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///   disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///   @odata.etag: string, # Optional. The ETag of the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual Response GetSearchIndexer(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetSearchIndexer");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetSearchIndexerRequest(indexerName, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Lists all indexers available for a search service. </summary>
        /// <param name="select"> Selects which top-level properties of the indexers to retrieve. Specified as a comma-separated list of JSON property names, or &apos;*&apos; for all properties. The default is all properties. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetSearchIndexersAsync and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.GetSearchIndexersAsync();
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("credentials").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// ]]></code>
        /// This sample shows how to call GetSearchIndexersAsync with all parameters, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.GetSearchIndexersAsync("<select>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/List-Indexers
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>ListIndexersResult</c>:
        /// <code>{
        ///   value: [
        ///     {
        ///       name: string, # Required. The name of the indexer.
        ///       description: string, # Optional. The description of the indexer.
        ///       dataSource: {
        ///         name: string, # Required. The name of the datasource.
        ///         description: string, # Optional. The description of the datasource.
        ///         type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///         credentials: {
        ///           connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///         }, # Required. Credentials for the datasource.
        ///         container: {
        ///           name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///           query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///         }, # Required. The data container for the datasource.
        ///         dataChangeDetectionPolicy: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///         }, # Optional. The data change detection policy for the datasource.
        ///         dataDeletionDetectionPolicy: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///         }, # Optional. The data deletion detection policy for the datasource.
        ///         @odata.etag: string, # Optional. The ETag of the data source.
        ///       }, # Required. The name of the datasource from which this indexer reads data.
        ///       skillset: {
        ///         name: string, # Required. The name of the skillset.
        ///         description: string, # Optional. The description of the skillset.
        ///         skills: [
        ///           {
        ///             @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///             name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///             description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///             context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///             inputs: [
        ///               {
        ///                 name: string, # Required. The name of the input.
        ///                 source: string, # Optional. The source of the input.
        ///                 sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///                 inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///               }
        ///             ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///             outputs: [
        ///               {
        ///                 name: string, # Required. The name of the output defined by the skill.
        ///                 targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///               }
        ///             ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///           }
        ///         ], # Required. A list of skills in the skillset.
        ///         cognitiveServices: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///           description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///         }, # Optional. Details about cognitive services to be used when running skills.
        ///         knowledgeStore: {
        ///           storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///           projections: [
        ///             {
        ///               tables: [
        ///                 {
        ///                   tableName: string, # Required. Name of the Azure table to store projected data in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure Table storage.
        ///               objects: [
        ///                 {
        ///                   storageContainer: string, # Required. Blob container to store projections in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure Blob storage.
        ///               files: [
        ///                 {
        ///                   storageContainer: string, # Required. Blob container to store projections in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure File storage.
        ///             }
        ///           ], # Required. A list of additional projections to perform during indexing.
        ///         }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///         @odata.etag: string, # Optional. The ETag of the skillset.
        ///       }, # Optional. The name of the skillset executing with this indexer.
        ///       schedule: {
        ///         interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///         startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///       }, # Optional. The schedule for this indexer.
        ///       parameters: {
        ///         batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///         maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///         maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///         configuration: {
        ///           parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///           excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///           indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///           failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///           failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///           indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///           delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///           delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///           firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///           documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///           dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///           imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///           allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///           pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///           executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///           queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///         }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///       }, # Optional. Parameters for indexer execution.
        ///       fieldMappings: [
        ///         {
        ///           sourceFieldName: string, # Required. The name of the field in the data source.
        ///           targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///           mappingFunction: {
        ///             name: string, # Required. The name of the field mapping function.
        ///             parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///           }, # Optional. A function to apply to each source field value before indexing.
        ///         }
        ///       ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///       outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///       disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///       @odata.etag: string, # Optional. The ETag of the indexer.
        ///     }
        ///   ], # Required. The indexers in the Search service.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual async Task<Response> GetSearchIndexersAsync(string select = null, RequestContext context = null)
        {
            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetSearchIndexers");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetSearchIndexersRequest(select, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Lists all indexers available for a search service. </summary>
        /// <param name="select"> Selects which top-level properties of the indexers to retrieve. Specified as a comma-separated list of JSON property names, or &apos;*&apos; for all properties. The default is all properties. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetSearchIndexers and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.GetSearchIndexers();
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("credentials").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// ]]></code>
        /// This sample shows how to call GetSearchIndexers with all parameters, and how to parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.GetSearchIndexers("<select>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("credentials").GetProperty("connectionString").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("container").GetProperty("query").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("dataChangeDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("dataDeletionDetectionPolicy").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("dataSource").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("context").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("skills")[0].GetProperty("outputs")[0].GetProperty("targetName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("@odata.type").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("cognitiveServices").GetProperty("description").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("storageConnectionString").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("tableName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("tables")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("objects")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("storageContainer").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("referenceKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("generatedKeyName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("source").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("knowledgeStore").GetProperty("projections")[0].GetProperty("files")[0].GetProperty("inputs")[0].GetProperty("inputs")[0].GetProperty("sourceContext").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("skillset").GetProperty("@odata.etag").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("schedule").GetProperty("interval").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("schedule").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("batchSize").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("maxFailedItems").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("maxFailedItemsPerBatch").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("parsingMode").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("excludedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("indexedFileNameExtensions").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnsupportedContentType").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("failOnUnprocessableDocument").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("indexStorageMetadataOnlyForOversizedDocuments").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("delimitedTextDelimiter").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("firstLineContainsHeaders").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("documentRoot").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("dataToExtract").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("imageAction").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("allowSkillsetToReadFileData").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("pdfTextRotationAlgorithm").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("executionEnvironment").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("parameters").GetProperty("configuration").GetProperty("queryTimeout").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("fieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("sourceFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("targetFieldName").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFieldMappings")[0].GetProperty("mappingFunction").GetProperty("parameters").GetProperty("<test>").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("disabled").ToString());
        /// Console.WriteLine(result.GetProperty("value")[0].GetProperty("@odata.etag").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/List-Indexers
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>ListIndexersResult</c>:
        /// <code>{
        ///   value: [
        ///     {
        ///       name: string, # Required. The name of the indexer.
        ///       description: string, # Optional. The description of the indexer.
        ///       dataSource: {
        ///         name: string, # Required. The name of the datasource.
        ///         description: string, # Optional. The description of the datasource.
        ///         type: &quot;azuresql&quot; | &quot;cosmosdb&quot; | &quot;azureblob&quot; | &quot;azuretable&quot; | &quot;mysql&quot; | &quot;adlsgen2&quot;, # Required. The type of the datasource.
        ///         credentials: {
        ///           connectionString: string, # Optional. The connection string for the datasource. Set to &apos;&lt;unchanged&gt;&apos; if you do not want the connection string updated.
        ///         }, # Required. Credentials for the datasource.
        ///         container: {
        ///           name: string, # Required. The name of the table or view (for Azure SQL data source) or collection (for CosmosDB data source) that will be indexed.
        ///           query: string, # Optional. A query that is applied to this data container. The syntax and meaning of this parameter is datasource-specific. Not supported by Azure SQL datasources.
        ///         }, # Required. The data container for the datasource.
        ///         dataChangeDetectionPolicy: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the data change detection policy.
        ///         }, # Optional. The data change detection policy for the datasource.
        ///         dataDeletionDetectionPolicy: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the data deletion detection policy.
        ///         }, # Optional. The data deletion detection policy for the datasource.
        ///         @odata.etag: string, # Optional. The ETag of the data source.
        ///       }, # Required. The name of the datasource from which this indexer reads data.
        ///       skillset: {
        ///         name: string, # Required. The name of the skillset.
        ///         description: string, # Optional. The description of the skillset.
        ///         skills: [
        ///           {
        ///             @odata.type: string, # Required. Identifies the concrete type of the skill.
        ///             name: string, # Optional. The name of the skill which uniquely identifies it within the skillset. A skill with no name defined will be given a default name of its 1-based index in the skills array, prefixed with the character &apos;#&apos;.
        ///             description: string, # Optional. The description of the skill which describes the inputs, outputs, and usage of the skill.
        ///             context: string, # Optional. Represents the level at which operations take place, such as the document root or document content (for example, /document or /document/content). The default is /document.
        ///             inputs: [
        ///               {
        ///                 name: string, # Required. The name of the input.
        ///                 source: string, # Optional. The source of the input.
        ///                 sourceContext: string, # Optional. The source context used for selecting recursive inputs.
        ///                 inputs: [InputFieldMappingEntry], # Optional. The recursive inputs used when creating a complex type.
        ///               }
        ///             ], # Required. Inputs of the skills could be a column in the source data set, or the output of an upstream skill.
        ///             outputs: [
        ///               {
        ///                 name: string, # Required. The name of the output defined by the skill.
        ///                 targetName: string, # Optional. The target name of the output. It is optional and default to name.
        ///               }
        ///             ], # Required. The output of a skill is either a field in a search index, or a value that can be consumed as an input by another skill.
        ///           }
        ///         ], # Required. A list of skills in the skillset.
        ///         cognitiveServices: {
        ///           @odata.type: string, # Required. Identifies the concrete type of the cognitive service resource attached to a skillset.
        ///           description: string, # Optional. Description of the cognitive service resource attached to a skillset.
        ///         }, # Optional. Details about cognitive services to be used when running skills.
        ///         knowledgeStore: {
        ///           storageConnectionString: string, # Required. The connection string to the storage account projections will be stored in.
        ///           projections: [
        ///             {
        ///               tables: [
        ///                 {
        ///                   tableName: string, # Required. Name of the Azure table to store projected data in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure Table storage.
        ///               objects: [
        ///                 {
        ///                   storageContainer: string, # Required. Blob container to store projections in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure Blob storage.
        ///               files: [
        ///                 {
        ///                   storageContainer: string, # Required. Blob container to store projections in.
        ///                   referenceKeyName: string, # Optional. Name of reference key to different projection.
        ///                   generatedKeyName: string, # Optional. Name of generated key to store projection under.
        ///                   source: string, # Optional. Source data to project.
        ///                   sourceContext: string, # Optional. Source context for complex projections.
        ///                   inputs: [InputFieldMappingEntry], # Optional. Nested inputs for complex projections.
        ///                 }
        ///               ], # Optional. Projections to Azure File storage.
        ///             }
        ///           ], # Required. A list of additional projections to perform during indexing.
        ///         }, # Optional. Definition of additional projections to azure blob, table, or files, of enriched data.
        ///         @odata.etag: string, # Optional. The ETag of the skillset.
        ///       }, # Optional. The name of the skillset executing with this indexer.
        ///       schedule: {
        ///         interval: string (duration ISO 8601 Format), # Required. The interval of time between indexer executions.
        ///         startTime: string (ISO 8601 Format), # Optional. The time when an indexer should start running.
        ///       }, # Optional. The schedule for this indexer.
        ///       parameters: {
        ///         batchSize: number, # Optional. The number of items that are read from the data source and indexed as a single batch in order to improve performance. The default depends on the data source type.
        ///         maxFailedItems: number, # Optional. The maximum number of items that can fail indexing for indexer execution to still be considered successful. -1 means no limit. Default is 0.
        ///         maxFailedItemsPerBatch: number, # Optional. The maximum number of items in a single batch that can fail indexing for the batch to still be considered successful. -1 means no limit. Default is 0.
        ///         configuration: {
        ///           parsingMode: &quot;default&quot; | &quot;text&quot; | &quot;delimitedText&quot; | &quot;json&quot; | &quot;jsonArray&quot; | &quot;jsonLines&quot;, # Optional. Represents the parsing mode for indexing from an Azure blob data source.
        ///           excludedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to ignore when processing from Azure blob storage.  For example, you could exclude &quot;.png, .mp4&quot; to skip over those files during indexing.
        ///           indexedFileNameExtensions: string, # Optional. Comma-delimited list of filename extensions to select when processing from Azure blob storage.  For example, you could focus indexing on specific application files &quot;.docx, .pptx, .msg&quot; to specifically include those file types.
        ///           failOnUnsupportedContentType: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing when an unsupported content type is encountered, and you don&apos;t know all the content types (file extensions) in advance.
        ///           failOnUnprocessableDocument: boolean, # Optional. For Azure blobs, set to false if you want to continue indexing if a document fails indexing.
        ///           indexStorageMetadataOnlyForOversizedDocuments: boolean, # Optional. For Azure blobs, set this property to true to still index storage metadata for blob content that is too large to process. Oversized blobs are treated as errors by default. For limits on blob size, see https://docs.microsoft.com/azure/search/search-limits-quotas-capacity.
        ///           delimitedTextHeaders: string, # Optional. For CSV blobs, specifies a comma-delimited list of column headers, useful for mapping source fields to destination fields in an index.
        ///           delimitedTextDelimiter: string, # Optional. For CSV blobs, specifies the end-of-line single-character delimiter for CSV files where each line starts a new document (for example, &quot;|&quot;).
        ///           firstLineContainsHeaders: boolean, # Optional. For CSV blobs, indicates that the first (non-blank) line of each blob contains headers.
        ///           documentRoot: string, # Optional. For JSON arrays, given a structured or semi-structured document, you can specify a path to the array using this property.
        ///           dataToExtract: &quot;storageMetadata&quot; | &quot;allMetadata&quot; | &quot;contentAndMetadata&quot;, # Optional. Specifies the data to extract from Azure blob storage and tells the indexer which data to extract from image content when &quot;imageAction&quot; is set to a value other than &quot;none&quot;.  This applies to embedded image content in a .PDF or other application, or image files such as .jpg and .png, in Azure blobs.
        ///           imageAction: &quot;none&quot; | &quot;generateNormalizedImages&quot; | &quot;generateNormalizedImagePerPage&quot;, # Optional. Determines how to process embedded images and image files in Azure blob storage.  Setting the &quot;imageAction&quot; configuration to any value other than &quot;none&quot; requires that a skillset also be attached to that indexer.
        ///           allowSkillsetToReadFileData: boolean, # Optional. If true, will create a path //document//file_data that is an object representing the original file data downloaded from your blob data source.  This allows you to pass the original file data to a custom skill for processing within the enrichment pipeline, or to the Document Extraction skill.
        ///           pdfTextRotationAlgorithm: &quot;none&quot; | &quot;detectAngles&quot;, # Optional. Determines algorithm for text extraction from PDF files in Azure blob storage.
        ///           executionEnvironment: &quot;standard&quot; | &quot;private&quot;, # Optional. Specifies the environment in which the indexer should execute.
        ///           queryTimeout: string, # Optional. Increases the timeout beyond the 5-minute default for Azure SQL database data sources, specified in the format &quot;hh:mm:ss&quot;.
        ///         }, # Optional. A dictionary of indexer-specific configuration properties. Each name is the name of a specific property. Each value must be of a primitive type.
        ///       }, # Optional. Parameters for indexer execution.
        ///       fieldMappings: [
        ///         {
        ///           sourceFieldName: string, # Required. The name of the field in the data source.
        ///           targetFieldName: string, # Optional. The name of the target field in the index. Same as the source field name by default.
        ///           mappingFunction: {
        ///             name: string, # Required. The name of the field mapping function.
        ///             parameters: Dictionary&lt;string, AnyObject&gt;, # Optional. A dictionary of parameter name/value pairs to pass to the function. Each value must be of a primitive type.
        ///           }, # Optional. A function to apply to each source field value before indexing.
        ///         }
        ///       ], # Optional. Defines mappings between fields in the data source and corresponding target fields in the index.
        ///       outputFieldMappings: [FieldMapping], # Optional. Output field mappings are applied after enrichment and immediately before indexing.
        ///       disabled: boolean, # Optional. A value indicating whether the indexer is disabled. Default is false.
        ///       @odata.etag: string, # Optional. The ETag of the indexer.
        ///     }
        ///   ], # Required. The indexers in the Search service.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual Response GetSearchIndexers(string select = null, RequestContext context = null)
        {
            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetSearchIndexers");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetSearchIndexersRequest(select, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Returns the current status and execution history of an indexer. </summary>
        /// <param name="indexerName"> The name of the indexer for which to retrieve status. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetStatusAsync with required parameters and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = await client.GetStatusAsync("<indexerName>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("endTime").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("statusCode").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("message").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("itemsProcessed").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("itemsFailed").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("initialTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("finalTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("endTime").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("statusCode").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("message").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("itemsProcessed").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("itemsFailed").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("initialTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("finalTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxRunTime").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxDocumentExtractionSize").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxDocumentContentCharactersToExtract").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Get-Indexer-Status
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexerStatus</c>:
        /// <code>{
        ///   status: &quot;unknown&quot; | &quot;error&quot; | &quot;running&quot;, # Required. Overall indexer status.
        ///   lastResult: {
        ///     status: &quot;transientFailure&quot; | &quot;success&quot; | &quot;inProgress&quot; | &quot;reset&quot;, # Required. The outcome of this indexer execution.
        ///     errorMessage: string, # Optional. The error message indicating the top-level error, if any.
        ///     startTime: string (ISO 8601 Format), # Optional. The start time of this indexer execution.
        ///     endTime: string (ISO 8601 Format), # Optional. The end time of this indexer execution, if the execution has already completed.
        ///     errors: [
        ///       {
        ///         key: string, # Optional. The key of the item for which indexing failed.
        ///         errorMessage: string, # Required. The message describing the error that occurred while processing the item.
        ///         statusCode: number, # Required. The status code indicating why the indexing operation failed. Possible values include: 400 for a malformed input document, 404 for document not found, 409 for a version conflict, 422 when the index is temporarily unavailable, or 503 for when the service is too busy.
        ///         name: string, # Optional. The name of the source at which the error originated. For example, this could refer to a particular skill in the attached skillset. This may not be always available.
        ///         details: string, # Optional. Additional, verbose details about the error to assist in debugging the indexer. This may not be always available.
        ///         documentationLink: string, # Optional. A link to a troubleshooting guide for these classes of errors. This may not be always available.
        ///       }
        ///     ], # Required. The item-level indexing errors.
        ///     warnings: [
        ///       {
        ///         key: string, # Optional. The key of the item which generated a warning.
        ///         message: string, # Required. The message describing the warning that occurred while processing the item.
        ///         name: string, # Optional. The name of the source at which the warning originated. For example, this could refer to a particular skill in the attached skillset. This may not be always available.
        ///         details: string, # Optional. Additional, verbose details about the warning to assist in debugging the indexer. This may not be always available.
        ///         documentationLink: string, # Optional. A link to a troubleshooting guide for these classes of warnings. This may not be always available.
        ///       }
        ///     ], # Required. The item-level indexing warnings.
        ///     itemsProcessed: number, # Required. The number of items that were processed during this indexer execution. This includes both successfully processed items and items where indexing was attempted but failed.
        ///     itemsFailed: number, # Required. The number of items that failed to be indexed during this indexer execution.
        ///     initialTrackingState: string, # Optional. Change tracking state with which an indexer execution started.
        ///     finalTrackingState: string, # Optional. Change tracking state with which an indexer execution finished.
        ///   }, # Optional. The result of the most recent or an in-progress indexer execution.
        ///   executionHistory: [IndexerExecutionResult], # Required. History of the recent indexer executions, sorted in reverse chronological order.
        ///   limits: {
        ///     maxRunTime: string (duration ISO 8601 Format), # Optional. The maximum duration that the indexer is permitted to run for one execution.
        ///     maxDocumentExtractionSize: number, # Optional. The maximum size of a document, in bytes, which will be considered valid for indexing.
        ///     maxDocumentContentCharactersToExtract: number, # Optional. The maximum number of characters that will be extracted from a document picked up for indexing.
        ///   }, # Required. The execution limits for the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual async Task<Response> GetStatusAsync(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetStatus");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetStatusRequest(indexerName, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary> Returns the current status and execution history of an indexer. </summary>
        /// <param name="indexerName"> The name of the indexer for which to retrieve status. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="indexerName"/> is null. </exception>
        /// <exception cref="ArgumentException"> <paramref name="indexerName"/> is an empty string, and was expected to be non-empty. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. Details of the response body schema are in the Remarks section below. </returns>
        /// <example>
        /// This sample shows how to call GetStatus with required parameters and parse the result.
        /// <code><![CDATA[
        /// var client = new SearchIndexerClient("<https://my-service.azure.com>");
        /// 
        /// Response response = client.GetStatus("<indexerName>");
        /// 
        /// JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
        /// Console.WriteLine(result.GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("endTime").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("statusCode").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("errors")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("message").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("warnings")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("itemsProcessed").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("itemsFailed").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("initialTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("lastResult").GetProperty("finalTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("status").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("startTime").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("endTime").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("errorMessage").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("statusCode").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("errors")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("key").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("message").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("name").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("details").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("warnings")[0].GetProperty("documentationLink").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("itemsProcessed").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("itemsFailed").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("initialTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("executionHistory")[0].GetProperty("finalTrackingState").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxRunTime").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxDocumentExtractionSize").ToString());
        /// Console.WriteLine(result.GetProperty("limits").GetProperty("maxDocumentContentCharactersToExtract").ToString());
        /// ]]></code>
        /// </example>
        /// <remarks>
        /// Below is the JSON schema for the response payload.
        /// Additional information can be found in the service REST API documentation:
        /// https://docs.microsoft.com/rest/api/searchservice/Get-Indexer-Status
        /// 
        /// Response Body:
        /// 
        /// Schema for <c>SearchIndexerStatus</c>:
        /// <code>{
        ///   status: &quot;unknown&quot; | &quot;error&quot; | &quot;running&quot;, # Required. Overall indexer status.
        ///   lastResult: {
        ///     status: &quot;transientFailure&quot; | &quot;success&quot; | &quot;inProgress&quot; | &quot;reset&quot;, # Required. The outcome of this indexer execution.
        ///     errorMessage: string, # Optional. The error message indicating the top-level error, if any.
        ///     startTime: string (ISO 8601 Format), # Optional. The start time of this indexer execution.
        ///     endTime: string (ISO 8601 Format), # Optional. The end time of this indexer execution, if the execution has already completed.
        ///     errors: [
        ///       {
        ///         key: string, # Optional. The key of the item for which indexing failed.
        ///         errorMessage: string, # Required. The message describing the error that occurred while processing the item.
        ///         statusCode: number, # Required. The status code indicating why the indexing operation failed. Possible values include: 400 for a malformed input document, 404 for document not found, 409 for a version conflict, 422 when the index is temporarily unavailable, or 503 for when the service is too busy.
        ///         name: string, # Optional. The name of the source at which the error originated. For example, this could refer to a particular skill in the attached skillset. This may not be always available.
        ///         details: string, # Optional. Additional, verbose details about the error to assist in debugging the indexer. This may not be always available.
        ///         documentationLink: string, # Optional. A link to a troubleshooting guide for these classes of errors. This may not be always available.
        ///       }
        ///     ], # Required. The item-level indexing errors.
        ///     warnings: [
        ///       {
        ///         key: string, # Optional. The key of the item which generated a warning.
        ///         message: string, # Required. The message describing the warning that occurred while processing the item.
        ///         name: string, # Optional. The name of the source at which the warning originated. For example, this could refer to a particular skill in the attached skillset. This may not be always available.
        ///         details: string, # Optional. Additional, verbose details about the warning to assist in debugging the indexer. This may not be always available.
        ///         documentationLink: string, # Optional. A link to a troubleshooting guide for these classes of warnings. This may not be always available.
        ///       }
        ///     ], # Required. The item-level indexing warnings.
        ///     itemsProcessed: number, # Required. The number of items that were processed during this indexer execution. This includes both successfully processed items and items where indexing was attempted but failed.
        ///     itemsFailed: number, # Required. The number of items that failed to be indexed during this indexer execution.
        ///     initialTrackingState: string, # Optional. Change tracking state with which an indexer execution started.
        ///     finalTrackingState: string, # Optional. Change tracking state with which an indexer execution finished.
        ///   }, # Optional. The result of the most recent or an in-progress indexer execution.
        ///   executionHistory: [IndexerExecutionResult], # Required. History of the recent indexer executions, sorted in reverse chronological order.
        ///   limits: {
        ///     maxRunTime: string (duration ISO 8601 Format), # Optional. The maximum duration that the indexer is permitted to run for one execution.
        ///     maxDocumentExtractionSize: number, # Optional. The maximum size of a document, in bytes, which will be considered valid for indexing.
        ///     maxDocumentContentCharactersToExtract: number, # Optional. The maximum number of characters that will be extracted from a document picked up for indexing.
        ///   }, # Required. The execution limits for the indexer.
        /// }
        /// </code>
        /// 
        /// </remarks>
        public virtual Response GetStatus(string indexerName, RequestContext context = null)
        {
            Argument.AssertNotNullOrEmpty(indexerName, nameof(indexerName));

            using var scope = ClientDiagnostics.CreateScope("SearchIndexerClient.GetStatus");
            scope.Start();
            try
            {
                using HttpMessage message = CreateGetStatusRequest(indexerName, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        internal HttpMessage CreateResetRequest(string indexerName, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier204);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers('", false);
            uri.AppendPath(indexerName, true);
            uri.AppendPath("')/search.reset", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            return message;
        }

        internal HttpMessage CreateRunRequest(string indexerName, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier202);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers('", false);
            uri.AppendPath(indexerName, true);
            uri.AppendPath("')/search.run", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            return message;
        }

        internal HttpMessage CreateCreateOrUpdateRequest(string indexerName, RequestContent content, MatchConditions matchConditions, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200201);
            var request = message.Request;
            request.Method = RequestMethod.Put;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers('", false);
            uri.AppendPath(indexerName, true);
            uri.AppendPath("')", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Prefer", "return=representation");
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            if (matchConditions != null)
            {
                request.Headers.Add(matchConditions);
            }
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        internal HttpMessage CreateGetSearchIndexerRequest(string indexerName, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers('", false);
            uri.AppendPath(indexerName, true);
            uri.AppendPath("')", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            return message;
        }

        internal HttpMessage CreateGetSearchIndexersRequest(string select, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers", false);
            if (select != null)
            {
                uri.AppendQuery("$select", select, true);
            }
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            return message;
        }

        internal HttpMessage CreateGetStatusRequest(string indexerName, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Get;
            var uri = new RawRequestUriBuilder();
            uri.AppendRaw(_endpoint, false);
            uri.AppendPath("/indexers('", false);
            uri.AppendPath(indexerName, true);
            uri.AppendPath("')/search.status", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json; odata.metadata=minimal");
            return message;
        }

        private static ResponseClassifier _responseClassifier204;
        private static ResponseClassifier ResponseClassifier204 => _responseClassifier204 ??= new StatusCodeClassifier(stackalloc ushort[] { 204 });
        private static ResponseClassifier _responseClassifier202;
        private static ResponseClassifier ResponseClassifier202 => _responseClassifier202 ??= new StatusCodeClassifier(stackalloc ushort[] { 202 });
        private static ResponseClassifier _responseClassifier200201;
        private static ResponseClassifier ResponseClassifier200201 => _responseClassifier200201 ??= new StatusCodeClassifier(stackalloc ushort[] { 200, 201 });
        private static ResponseClassifier _responseClassifier200;
        private static ResponseClassifier ResponseClassifier200 => _responseClassifier200 ??= new StatusCodeClassifier(stackalloc ushort[] { 200 });
    }
}
